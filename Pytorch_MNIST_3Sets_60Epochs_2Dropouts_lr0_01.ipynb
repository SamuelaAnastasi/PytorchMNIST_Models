{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_MNIST_3Sets_60Epochs_2Dropouts_lr0_01.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelaAnastasi/PytorchMNIST_Models/blob/master/Pytorch_MNIST_3Sets_60Epochs_2Dropouts_lr0_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJGXBvy4ZkYU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import libraries\n",
        "import torch as th\n",
        "import numpy as np\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrnA8gH9cU0z",
        "colab_type": "text"
      },
      "source": [
        "#Load and Visualize the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPJjF1CdcFXg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0\n",
        "\n",
        "# how many samples for batch to load - Q: Try with different batch size to see effects\n",
        "batch_size = 20\n",
        "\n",
        "# percentage of training set to use as validation\n",
        "valid_size = 0.2\n",
        "\n",
        "# convert data to Torch.FloatTensor\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "\n",
        "# define train and test datasets - define the root as 'data'\n",
        "train_set = datasets.MNIST(root='data', train=True,  download=True, transform=transform)\n",
        "test_set = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n",
        "\n",
        "# obtain training indices that will be used for validation\n",
        "num_train = len(train_set)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "# define samplers for obtaining training and validation batches\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "# define loaders that load the data\n",
        "train_loader = th.utils.data.DataLoader(train_set, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "valid_loader = th.utils.data.DataLoader(train_set, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
        "test_loader = th.utils.data.DataLoader(test_set, batch_size=batch_size, num_workers=num_workers, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vKjZQMcskzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# visualise the loaded data\n",
        "import matplotlib.pyplot as plot\n",
        "\n",
        "# get one batch of train images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "images = images.numpy()\n",
        "\n",
        "# plot images and labels in the batch \n",
        "fig = plot.figure(figsize=(25, 4))\n",
        "\n",
        "for indx in np.arange(20):\n",
        "  ax = fig.add_subplot(2, 20/2, indx+1, xticks=[], yticks=[])\n",
        "  ax.imshow(np.squeeze(images[indx]), cmap='gray') \n",
        "  ax.set_title(str(labels[indx].item()), color='white')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahN7hXXgcZZI",
        "colab_type": "text"
      },
      "source": [
        "#Define the Network  Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTzYpCO_43aR",
        "colab_type": "code",
        "outputId": "15b409d0-7b89-4b98-9f0c-0e5e5f50b937",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# define model network clas\n",
        "class Network(nn.Module):\n",
        "  \n",
        "  # include all layers on __init__()\n",
        "  def __init__(self):\n",
        "    # call super __init_()\n",
        "    super(Network, self).__init__()\n",
        "    \n",
        "    # 3 fully connected Layer hidden and output\n",
        "    self.fc1 = nn.Linear(28*28, 512)\n",
        "    self.fc2 = nn.Linear(512, 128)\n",
        "    self.fc3 = nn.Linear(128, 10)\n",
        "    \n",
        "    # dropout to prevent overfitting \n",
        "    self.dropout = nn.Dropout(0.2)\n",
        "    \n",
        "    # define forward behavior of network - that is how the input x \n",
        "    #is going to be passed to layers and transformed\n",
        "    \n",
        "  def forward(self, x):\n",
        "    # flatten input\n",
        "#       x = x.view(-1, 28 * 28)\n",
        "      \n",
        "      # pass input to the layers\n",
        "      x = F.relu(self.fc1(x))\n",
        "      x = self.dropout(x)\n",
        "      x = F.relu(self.fc2(x))\n",
        "      x = self.dropout(x)\n",
        "      x = self.fc3(x)\n",
        "      x = F.log_softmax(x, dim=1)\n",
        "      \n",
        "      return x      \n",
        "      \n",
        "model = Network()\n",
        "print(model)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network(\n",
            "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.2)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oCETSyqLnfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(model.fc1.weight)\n",
        "print(model.fc1.bias)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRqJPM97V8Tm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim\n",
        "# define loss\n",
        "criterion = nn.NLLLoss()\n",
        "# define optimizer Q. useful use alternative optimizers for this kind of data?\n",
        "opt = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfPgg3Mpcu55",
        "colab_type": "text"
      },
      "source": [
        "#Train the Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LllWbjWMYmRY",
        "colab_type": "code",
        "outputId": "caca4b3f-a29f-4fa1-8602-e6ac4aeec938",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# times the model sees all entries all training data heare all images are seen 60 times\n",
        "epochs = 60\n",
        "\n",
        "# initialize tracker for minimum validation loss\n",
        "valid_loss_min = np.Inf # set initial \"min\" to infinity\n",
        "\n",
        "#model.train()\n",
        "\n",
        "train_losses, valid_losses = [], []\n",
        "\n",
        "for e in range(epochs):\n",
        "  \n",
        "  train_loss = 0.0\n",
        "  valid_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    \n",
        "  model.train()  \n",
        "  for images, labels in train_loader:\n",
        "    images = images.view(images.shape[0], -1)\n",
        "    \n",
        "    opt.zero_grad()\n",
        "    \n",
        "    output = model.forward(images)\n",
        "    loss = criterion(output, labels)\n",
        "    loss.backward()    \n",
        "    opt.step()\n",
        "    \n",
        "    #accumulate loss from each batch\n",
        "    train_loss += loss.item()*images.size(0)\n",
        "    \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "  model.eval()     \n",
        "  for images, labels in valid_loader:\n",
        "    \n",
        "    images = images.view(images.shape[0], -1)\n",
        "    \n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = model.forward(images)\n",
        "    # calculate the loss\n",
        "    loss = criterion(output, labels)\n",
        "    # update running validation loss \n",
        "    valid_loss += loss.item()*images.size(0)\n",
        "  \n",
        "  # print training/validation statistics \n",
        "  # calculate average loss over an epoch\n",
        "  train_loss = train_loss/len(train_loader.sampler)\n",
        "  valid_loss = valid_loss/len(valid_loader.sampler)\n",
        "  \n",
        "  \n",
        "  train_losses.append(train_loss/len(train_loader.sampler))\n",
        "  valid_losses.append(valid_loss/len(valid_loader.sampler))\n",
        "  \n",
        "  print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        e+1, \n",
        "        train_loss,\n",
        "        valid_loss\n",
        "        ))\n",
        "  \n",
        "  # save model if validation loss has decreased\n",
        "  if valid_loss <= valid_loss_min and (valid_loss_min - valid_loss) > 0.05:\n",
        "    print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "    valid_loss_min,\n",
        "    valid_loss))\n",
        "    th.save(model.state_dict(), 'model.pt')\n",
        "    valid_loss_min = valid_loss"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 1.314246 \tValidation Loss: 0.600838\n",
            "Validation loss decreased (inf --> 0.600838).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 0.547838 \tValidation Loss: 0.404959\n",
            "Validation loss decreased (0.600838 --> 0.404959).  Saving model ...\n",
            "Epoch: 3 \tTraining Loss: 0.433435 \tValidation Loss: 0.328665\n",
            "Validation loss decreased (0.404959 --> 0.328665).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 0.375586 \tValidation Loss: 0.292487\n",
            "Epoch: 5 \tTraining Loss: 0.333926 \tValidation Loss: 0.269359\n",
            "Validation loss decreased (0.328665 --> 0.269359).  Saving model ...\n",
            "Epoch: 6 \tTraining Loss: 0.312713 \tValidation Loss: 0.246191\n",
            "Epoch: 7 \tTraining Loss: 0.279591 \tValidation Loss: 0.221821\n",
            "Epoch: 8 \tTraining Loss: 0.263137 \tValidation Loss: 0.199761\n",
            "Validation loss decreased (0.269359 --> 0.199761).  Saving model ...\n",
            "Epoch: 9 \tTraining Loss: 0.243613 \tValidation Loss: 0.182286\n",
            "Epoch: 10 \tTraining Loss: 0.224358 \tValidation Loss: 0.165949\n",
            "Epoch: 11 \tTraining Loss: 0.207228 \tValidation Loss: 0.150846\n",
            "Epoch: 12 \tTraining Loss: 0.190257 \tValidation Loss: 0.146739\n",
            "Validation loss decreased (0.199761 --> 0.146739).  Saving model ...\n",
            "Epoch: 13 \tTraining Loss: 0.176934 \tValidation Loss: 0.138453\n",
            "Epoch: 14 \tTraining Loss: 0.163568 \tValidation Loss: 0.119739\n",
            "Epoch: 15 \tTraining Loss: 0.155820 \tValidation Loss: 0.116023\n",
            "Epoch: 16 \tTraining Loss: 0.142931 \tValidation Loss: 0.105285\n",
            "Epoch: 17 \tTraining Loss: 0.140447 \tValidation Loss: 0.093380\n",
            "Validation loss decreased (0.146739 --> 0.093380).  Saving model ...\n",
            "Epoch: 18 \tTraining Loss: 0.129024 \tValidation Loss: 0.086351\n",
            "Epoch: 19 \tTraining Loss: 0.121070 \tValidation Loss: 0.083397\n",
            "Epoch: 20 \tTraining Loss: 0.116604 \tValidation Loss: 0.086935\n",
            "Epoch: 21 \tTraining Loss: 0.109799 \tValidation Loss: 0.073937\n",
            "Epoch: 22 \tTraining Loss: 0.100799 \tValidation Loss: 0.073287\n",
            "Epoch: 23 \tTraining Loss: 0.100134 \tValidation Loss: 0.061806\n",
            "Epoch: 24 \tTraining Loss: 0.093030 \tValidation Loss: 0.058346\n",
            "Epoch: 25 \tTraining Loss: 0.089956 \tValidation Loss: 0.054081\n",
            "Epoch: 26 \tTraining Loss: 0.082418 \tValidation Loss: 0.050079\n",
            "Epoch: 27 \tTraining Loss: 0.081060 \tValidation Loss: 0.054625\n",
            "Epoch: 28 \tTraining Loss: 0.074638 \tValidation Loss: 0.042927\n",
            "Validation loss decreased (0.093380 --> 0.042927).  Saving model ...\n",
            "Epoch: 29 \tTraining Loss: 0.068132 \tValidation Loss: 0.047354\n",
            "Epoch: 30 \tTraining Loss: 0.069563 \tValidation Loss: 0.036385\n",
            "Epoch: 31 \tTraining Loss: 0.064866 \tValidation Loss: 0.034446\n",
            "Epoch: 32 \tTraining Loss: 0.060746 \tValidation Loss: 0.033788\n",
            "Epoch: 33 \tTraining Loss: 0.060925 \tValidation Loss: 0.030621\n",
            "Epoch: 34 \tTraining Loss: 0.054023 \tValidation Loss: 0.029306\n",
            "Epoch: 35 \tTraining Loss: 0.051797 \tValidation Loss: 0.026420\n",
            "Epoch: 36 \tTraining Loss: 0.051125 \tValidation Loss: 0.026275\n",
            "Epoch: 37 \tTraining Loss: 0.049674 \tValidation Loss: 0.024175\n",
            "Epoch: 38 \tTraining Loss: 0.045975 \tValidation Loss: 0.022792\n",
            "Epoch: 39 \tTraining Loss: 0.046553 \tValidation Loss: 0.022172\n",
            "Epoch: 40 \tTraining Loss: 0.041757 \tValidation Loss: 0.020629\n",
            "Epoch: 41 \tTraining Loss: 0.040061 \tValidation Loss: 0.019240\n",
            "Epoch: 42 \tTraining Loss: 0.038629 \tValidation Loss: 0.018473\n",
            "Epoch: 43 \tTraining Loss: 0.035309 \tValidation Loss: 0.018180\n",
            "Epoch: 44 \tTraining Loss: 0.034649 \tValidation Loss: 0.015227\n",
            "Epoch: 45 \tTraining Loss: 0.034745 \tValidation Loss: 0.015360\n",
            "Epoch: 46 \tTraining Loss: 0.032689 \tValidation Loss: 0.013996\n",
            "Epoch: 47 \tTraining Loss: 0.029761 \tValidation Loss: 0.011750\n",
            "Epoch: 48 \tTraining Loss: 0.032506 \tValidation Loss: 0.013498\n",
            "Epoch: 49 \tTraining Loss: 0.030410 \tValidation Loss: 0.011279\n",
            "Epoch: 50 \tTraining Loss: 0.027289 \tValidation Loss: 0.011522\n",
            "Epoch: 51 \tTraining Loss: 0.028824 \tValidation Loss: 0.009709\n",
            "Epoch: 52 \tTraining Loss: 0.026853 \tValidation Loss: 0.008375\n",
            "Epoch: 53 \tTraining Loss: 0.024316 \tValidation Loss: 0.008937\n",
            "Epoch: 54 \tTraining Loss: 0.024313 \tValidation Loss: 0.007992\n",
            "Epoch: 55 \tTraining Loss: 0.023311 \tValidation Loss: 0.009606\n",
            "Epoch: 56 \tTraining Loss: 0.020728 \tValidation Loss: 0.006577\n",
            "Epoch: 57 \tTraining Loss: 0.021828 \tValidation Loss: 0.007721\n",
            "Epoch: 58 \tTraining Loss: 0.020471 \tValidation Loss: 0.005841\n",
            "Epoch: 59 \tTraining Loss: 0.022426 \tValidation Loss: 0.006590\n",
            "Epoch: 60 \tTraining Loss: 0.021140 \tValidation Loss: 0.010209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz1jKaLRZXj5",
        "colab_type": "text"
      },
      "source": [
        "##Load the Model with the Lowest Validation Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii3636RKZaoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_state_dict(th.load('model.pt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SWk-Yb06oXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy Udacity's helper file in a cell\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "def test_network(net, trainloader):\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
        "\n",
        "    dataiter = iter(trainloader)\n",
        "    images, labels = dataiter.next()\n",
        "\n",
        "    # Create Variables for the inputs and targets\n",
        "    inputs = Variable(images)\n",
        "    targets = Variable(images)\n",
        "\n",
        "    # Clear the gradients from all Variables\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass, then backward pass, then update weights\n",
        "    output = net.forward(inputs)\n",
        "    loss = criterion(output, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    if normalize:\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        image = std * image + mean\n",
        "        image = np.clip(image, 0, 1)\n",
        "\n",
        "    ax.imshow(image)\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_visible(False)\n",
        "    ax.spines['bottom'].set_visible(False)\n",
        "    ax.tick_params(axis='both', length=0)\n",
        "    ax.set_xticklabels('')\n",
        "    ax.set_yticklabels('')\n",
        "\n",
        "    return ax\n",
        "\n",
        "\n",
        "def view_recon(img, recon):\n",
        "    ''' Function for displaying an image (as a PyTorch Tensor) and its\n",
        "        reconstruction also a PyTorch Tensor\n",
        "    '''\n",
        "\n",
        "    fig, axes = plt.subplots(ncols=2, sharex=True, sharey=True)\n",
        "    axes[0].imshow(img.numpy().squeeze())\n",
        "    axes[1].imshow(recon.data.numpy().squeeze())\n",
        "    for ax in axes:\n",
        "        ax.axis('off')\n",
        "        ax.set_adjustable('box-forced')\n",
        "\n",
        "def view_classify(img, ps, version=\"MNIST\"):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(8,4), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.set_aspect(\"auto\")\n",
        "    \n",
        "    ax2.bar(np.arange(10), ps)\n",
        "    \n",
        "    fig.tight_layout()\n",
        "    ax1.axis('off')\n",
        "    \n",
        "    ax2.set_xticks(np.arange(10))\n",
        "    if version == \"MNIST\":\n",
        "        ax2.set_xticklabels(np.arange(10), color='white')\n",
        "        ax2.tick_params(labelcolor='white')\n",
        "    elif version == \"Fashion\":\n",
        "        ax2.set_xticklabels(['T-shirt/top',\n",
        "                            'Trouser',\n",
        "                            'Pullover',\n",
        "                            'Dress',\n",
        "                            'Coat',\n",
        "                            'Sandal',\n",
        "                            'Shirt',\n",
        "                            'Sneaker',\n",
        "                            'Bag',\n",
        "                            'Ankle Boot'], size='small');\n",
        "    ax2.set_title('Class Probability', color='white')\n",
        "    ax2.set_ylim(0, 1.1)\n",
        "    plt.tight_layout()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnzZTtU063BH",
        "colab_type": "code",
        "outputId": "87690717-4016-4b60-b49e-e52962433c5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "# get an image from test_loader and pass it through model for prediction\n",
        "images, labels = next(iter(test_loader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "# Turn off gradients to speed up this part\n",
        "with th.no_grad():\n",
        "    logps = model.forward(img)\n",
        "\n",
        "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "ps = th.exp(logps)\n",
        "view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAEYCAYAAABRMYxdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sk2AbjXeiOgu",
        "colab_type": "code",
        "outputId": "fc697dc3-d5fc-438f-d703-1f9b53f1232d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plot.plot(train_losses, label='Training loss')\n",
        "plot.plot(valid_losses, label='Validation loss')\n",
        "plot.legend(frameon=False)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f201f6a79e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAD8CAYAAABZ/vJZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njeRuAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQuCr8S1c-o3",
        "colab_type": "text"
      },
      "source": [
        "#Test the Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X-sZN3AdLBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize lists to monitor test loss and accuracy\n",
        "test_loss = 0.0\n",
        "# create lists to hold values for the total classes and correctly predicted classes\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "model.eval()\n",
        "for images, labels in test_loader:\n",
        "  # flatten images\n",
        "  images = images.view(images.shape[0], -1)\n",
        "  output = model.forward(images)\n",
        "  \n",
        "  loss = criterion(output, labels)\n",
        "  test_loss += loss.item()*images.size(0)\n",
        "  \n",
        "  # convert output probabilities to predicted class\n",
        "  _, preds = th.max(output, 1)\n",
        "  \n",
        "  # compare predictions to true label\n",
        "  correct = np.squeeze(preds.eq(labels.data.view_as(preds)))\n",
        "#   print(correct)\n",
        "  \n",
        "  # calculate test accuracy for each object class\n",
        "  for i in range(len(labels)):\n",
        "    label = labels.data[i]\n",
        "#     print(label)\n",
        "    class_correct[label] += correct[i].item()\n",
        "    class_total[label] += 1\n",
        "    \n",
        "    # calculate and print avg test loss\n",
        "test_loss = test_loss/len(test_loader.sampler)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            str(i), 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvuIZjbjujoc",
        "colab_type": "text"
      },
      "source": [
        "##Statistics - Training results\n",
        "\n",
        "* 3 sets - 60 Epochs - 2 dropouts - lr=0.01\n",
        "\n",
        "\n",
        "Test Loss: 0.124382\n",
        "\n",
        "--------------------------------------------------------------------------------------------------------\n",
        "\n",
        "Test Accuracy of     0: 98% (966/980)\n",
        "\n",
        "Test Accuracy of     1: 98% (1121/1135)\n",
        "\n",
        "Test Accuracy of     2: 96% (992/1032)\n",
        "\n",
        "Test Accuracy of     3: 95% (965/1010)\n",
        "\n",
        "Test Accuracy of     4: 94% (931/982)\n",
        "\n",
        "Test Accuracy of     5: 95% (852/892)\n",
        "\n",
        "Test Accuracy of     6: 96% (925/958)\n",
        "\n",
        "Test Accuracy of     7: 96% (994/1028)\n",
        "\n",
        "Test Accuracy of     8: 93% (911/974)\n",
        "\n",
        "Test Accuracy of     9: 95% (963/1009)\n",
        "\n",
        "----------------------------------------------------------------------------------------------------\n",
        "\n",
        "Test Accuracy (Overall): 96% (9620/10000)"
      ]
    }
  ]
}